{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ факторов успеваемости студентов\n",
    "\n",
    "## Введение\n",
    "\n",
    "Данный ноутбук содержит комплексный анализ факторов, влияющих на успеваемость студентов. Мы проведем:\n",
    "- Загрузку и первичный анализ данных\n",
    "- Статистический анализ\n",
    "- Построение и оценку предсказательной модели\n",
    "- Визуализацию результатов\n",
    "\n",
    "## Настройка окружения\n",
    "\n",
    "Сначала импортируем необходимые библиотеки и настроим параметры отображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Настройка отображения\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "# Настройка стиля графиков\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и первичный анализ данных\n",
    "\n",
    "### 1.1 Загрузка данных\n",
    "\n",
    "Загружаем датасет и проводим первичный осмотр данных. Это важный этап для понимания структуры и качества данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Загрузка данных из CSV файла с базовой проверкой\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(\"Данные успешно загружены\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных: {e}\")\n",
    "        return None\n",
    "\n",
    "data = load_data('data/StudentPerformanceFactors.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Исследовательский анализ данных (EDA)\n",
    "\n",
    "Проведем базовый анализ данных для понимания их структуры и распределения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Базовая информация о датасете\n",
    "print(\"\\nОбщая информация о датасете:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nСтатистическое описание числовых признаков:\")\n",
    "print(data.describe())\n",
    "\n",
    "print(\"\\nКоличество пропущенных значений:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Визуализация данных\n",
    "\n",
    "### 2.1 Распределение целевой переменной\n",
    "\n",
    "Визуализируем распределение оценок студентов для понимания общей картины успеваемости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Exam_Score'], kde=True)\n",
    "plt.title('Распределение итоговых оценок')\n",
    "plt.xlabel('Оценка')\n",
    "plt.ylabel('Частота')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Корреляционный анализ\n",
    "\n",
    "Построим тепловую карту корреляций для выявления взаимосвязей между признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Корреляционная матрица')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Предобработка данных\n",
    "\n",
    "Подготовим данные для моделирования, включая:\n",
    "- Обработку пропущенных значений\n",
    "- Кодирование категориальных переменных\n",
    "- Стандартизацию числовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"Комплексная предобработка данных\"\"\"\n",
    "    df = data.copy()\n",
    "    \n    # One-hot encoding для категориальных переменных\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "    \n    # Стандартизация числовых признаков\n",
    "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    numeric_features = [col for col in numeric_columns if col != 'Exam_Score']\n",
    "    \n    scaler = StandardScaler()\n",
    "    df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "    \n    return df, scaler\n",
    "\n",
    "data_processed, scaler = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Моделирование\n",
    "\n",
    "### 4.1 Подготовка данных для обучения\n",
    "\n",
    "Разделим данные на обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "X = data_processed.drop('Exam_Score', axis=1)\n",
    "y = data_processed['Exam_Score']\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Размеры выборок:\")\n",
    "print(f\"Обучающая выборка: {X_train.shape}\")\n",
    "print(f\"Валидационная выборка: {X_val.shape}\")\n",
    "print(f\"Тестовая выборка: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Подбор гиперпараметров\n",
    "\n",
    "Используем GridSearchCV для поиска оптимальных параметров модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'n_estimators': [100, 200],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Лучшие параметры:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Оценка модели\n",
    "\n",
    "Проведем комплексную оценку качества модели на всех выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_model(model, X, y, dataset_name):\n",
    "    \"\"\"Оценка качества модели на заданной выборке\"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    \n    print(f\"\\nРезультаты на {dataset_name} выборке:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "evaluate_model(best_model, X_train, y_train, \"обучающей\")\n",
    "evaluate_model(best_model, X_val, y_val, \"валидационной\")\n",
    "evaluate_model(best_model, X_test, y_test, \"тестовой\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Анализ важности признаков\n",
    "\n",
    "Визуализируем важность различных факторов для предсказания успеваемости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(10))\n",
    "plt.title('Топ-10 важных факторов')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Выводы и рекомендации\n",
    "\n",
    "На основе проведенного анализа можно сделать следующие выводы:\n",
    "\n",
    "1. Наиболее важные факторы успеваемости:\n",
    "   - Посещаемость занятий\n",
    "   - Количество часов самостоятельной подготовки\n",
    "   - Предыдущие академические результаты\n",
    "\n",
    "2. Демографические факторы оказывают минимальное влияние\n",
    "\n",
    "3. Рекомендации по улучшению успеваемости:\n",
    "   - Фокус на повышение посещаемости занятий\n",
    "   - Организация эффективного учебного времени\n",
    "   - Обеспечение доступа к образовательным ресурсам\n",
    "   - Вовлечение родителей в образовательный процесс\n",
    "\n",
    "## 8. Визуализация предсказаний\n",
    "\n",
    "Проанализируем качество предсказаний модели с помощью различных визуализаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_predictions(model, X_test, y_test):\n",
    "    \"\"\"Визуализация предсказаний модели\"\"\"\n",
    "    # Получаем предсказания\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n    # График сравнения реальных и предсказанных значений\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Реальные значения')\n",
    "    plt.ylabel('Предсказанные значения')\n",
    "    plt.title('Сравнение реальных и предсказанных значений')\n",
    "    plt.show()\n",
    "    \n    # График остатков\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(residuals, kde=True)\n",
    "    plt.xlabel('Остатки')\n",
    "    plt.ylabel('Частота')\n",
    "    plt.title('Распределение остатков')\n",
    "    plt.show()\n",
    "    \n    return residuals\n",
    "\n",
    "residuals = visualize_predictions(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Анализ ошибок модели\n",
    "\n",
    "Проанализируем, в каких случаях модель делает наибольшие ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_errors(X_test, y_test, y_pred, threshold=2):\n",
    "    \"\"\"Анализ случаев с большими ошибками предсказания\"\"\"\n",
    "    errors = np.abs(y_test - y_pred)\n",
    "    large_errors = errors > threshold * errors.std()\n",
    "    \n    error_analysis = pd.DataFrame({\n",
    "        'actual': y_test[large_errors],\n",
    "        'predicted': y_pred[large_errors],\n",
    "        'error': errors[large_errors]\n",
    "    })\n",
    "    \n    print(f\"Количество больших ошибок (>{threshold} std): {large_errors.sum()}\")\n",
    "    print(f\"Процент больших ошибок: {100 * large_errors.sum() / len(y_test):.2f}%\")\n",
    "    \n    return error_analysis\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "error_analysis = analyze_errors(X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Улучшение модели\n",
    "\n",
    "Рассмотрим возможные способы улучшения модели:\n",
    "\n",
    "1. Инженерия признаков:\n",
    "   - Создание взаимодействий между важными признаками\n",
    "   - Нелинейные преобразования числовых признаков\n",
    "   - Агрегация связанных характеристик\n",
    "\n",
    "2. Ансамблевые методы:\n",
    "   - Стекинг нескольких моделей\n",
    "   - Бэггинг для уменьшения переобучения\n",
    "   - Бустинг для улучшения точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_interaction_features(X):\n",
    "    \"\"\"Создание признаков взаимодействия\"\"\"\n",
    "    X = X.copy()\n",
    "    \n    # Добавляем взаимодействия между важными признаками\n",
    "    X['attendance_study'] = X['Attendance'] * X['Hours_Studied']\n",
    "    X['attendance_sleep'] = X['Attendance'] * X['Sleep_Hours']\n",
    "    X['study_sleep'] = X['Hours_Studied'] * X['Sleep_Hours']\n",
    "    \n    # Нелинейные преобразования\n",
    "    X['hours_studied_squared'] = X['Hours_Studied'] ** 2\n",
    "    X['attendance_squared'] = X['Attendance'] ** 2\n",
    "    \n    return X\n",
    "\n",
    "# Создаем новые признаки\n",
    "X_train_enhanced = create_interaction_features(X_train)\n",
    "X_test_enhanced = create_interaction_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Сохранение модели\n",
    "\n",
    "Сохраним лучшую модель и параметры предобработки для дальнейшего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "# Создаем директорию для моделей, если её нет\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Сохраняем модель и скейлер\n",
    "joblib.dump(best_model, 'models/student_performance_model.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "\n",
    "print(\"Модель и параметры предобработки сохранены в директории 'models'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Заключение\n",
    "\n",
    "В этом анализе мы:\n",
    "1. Провели комплексный анализ факторов успеваемости студентов\n",
    "2. Построили и оценили предсказательную модель\n",
    "3. Выявили ключевые факторы успеха\n",
    "4. Предложили рекомендации по улучшению успеваемости\n",
    "\n",
    "### Дальнейшие шаги:\n",
    "1. Сбор дополнительных данных о студентах\n",
    "2. Эксперименты с другими алгоритмами машинного обучения\n",
    "3. Разработка системы раннего предупреждения для студентов группы риска\n",
    "4. Создание интерактивного дашборда для мониторинга успеваемости"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
